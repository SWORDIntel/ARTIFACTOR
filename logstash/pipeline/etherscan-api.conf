# Logstash Pipeline Configuration for Etherscan API Logs

input {
  # Application logs
  file {
    path => "/app/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["etherscan-api", "application"]
    type => "application"
  }

  # Nginx access logs
  file {
    path => "/nginx/logs/access.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["nginx", "access"]
    type => "nginx-access"
  }

  # Nginx error logs
  file {
    path => "/nginx/logs/error.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    tags => ["nginx", "error"]
    type => "nginx-error"
  }

  # Beats input for future use
  beats {
    port => 5044
  }
}

filter {
  # Process application logs
  if [type] == "application" {
    mutate {
      add_field => { "service" => "etherscan-api" }
    }

    # Parse log level
    if [levelname] {
      mutate {
        add_field => { "log_level" => "%{levelname}" }
      }
    }

    # Extract request information if present
    if [message] =~ /GET|POST|PUT|DELETE/ {
      grok {
        match => {
          "message" => "%{WORD:http_method} %{URIPATH:request_path} - %{INT:status_code} - %{NUMBER:response_time}s"
        }
        tag_on_failure => ["_grokparsefailure_request"]
      }

      if [response_time] {
        mutate {
          convert => { "response_time" => "float" }
        }
      }

      if [status_code] {
        mutate {
          convert => { "status_code" => "integer" }
        }
      }
    }
  }

  # Process nginx access logs
  if [type] == "nginx-access" {
    mutate {
      add_field => { "service" => "nginx" }
    }

    # Convert numeric fields
    if [status] {
      mutate {
        convert => { "status" => "integer" }
      }
    }

    if [body_bytes_sent] {
      mutate {
        convert => { "body_bytes_sent" => "integer" }
      }
    }

    if [request_time] {
      mutate {
        convert => { "request_time" => "float" }
      }
    }

    # Parse user agent
    if [http_user_agent] {
      useragent {
        source => "http_user_agent"
        target => "user_agent"
      }
    }

    # GeoIP lookup for remote addresses
    if [remote_addr] and [remote_addr] !~ /^10\./ and [remote_addr] !~ /^192\.168\./ and [remote_addr] !~ /^172\./ {
      geoip {
        source => "remote_addr"
        target => "geoip"
      }
    }
  }

  # Process nginx error logs
  if [type] == "nginx-error" {
    grok {
      match => {
        "message" => "%{DATESTAMP:timestamp} \[%{WORD:log_level}\] %{GREEDYDATA:error_message}"
      }
      tag_on_failure => ["_grokparsefailure_nginx_error"]
    }

    mutate {
      add_field => { "service" => "nginx" }
    }
  }

  # Common fields for all logs
  mutate {
    add_field => {
      "environment" => "production"
      "project" => "etherscan-api"
    }
  }

  # Parse timestamp
  date {
    match => [ "time_local", "dd/MMM/yyyy:HH:mm:ss Z" ]
    target => "@timestamp"
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "path", "agent" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "etherscan-api-%{+YYYY.MM.dd}"
    template_name => "etherscan-api"
    template_pattern => "etherscan-api-*"
    template => "/usr/share/logstash/templates/etherscan-api.json"
    template_overwrite => true
  }

  # Debug output (remove in production)
  # stdout {
  #   codec => rubydebug
  # }
}